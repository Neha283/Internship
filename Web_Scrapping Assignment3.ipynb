{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e453382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product name you want to search on Amazon India: guitar\n",
      "Products found for 'guitar' on Amazon India:\n",
      "--------------------------------------------------\n",
      "Product:  Kadence rosewood Guitar Frontier Series, Electric Acoustic Black Guitar With EQ, Die Cast Keys, Set Of Strings, Strap, Picks And Bag (Black EQ, Electric Acoustic)\n",
      "Price: ₹ 4,899\n",
      "--------------------------------------------------\n",
      "Product:  Kadence Frontier guitar with Online Guitar learning course , Wine Red Acoustic Guitar with Die Cast Keys, Set of Strings, Strap, Picks and Bag (Wine Red, Acoustic)\n",
      "Price: ₹ 4,799\n",
      "--------------------------------------------------\n",
      "Product:  Kadence Slowhand Premium Jumbo Semi Acoustic Guitar with Heavy Padded Bag, guitar cable, Pro Capo (Black Spruce Wood)\n",
      "Price: ₹ 9,999\n",
      "--------------------------------------------------\n",
      "Product:  MOCKING BIRD 40 inch Acoustic guitar with Bag, Belt, Strings set and 5 Picks guitar for beginners musical instrument Cutaway Design gitaar\n",
      "Price: ₹ 5,489\n",
      "--------------------------------------------------\n",
      "Product:  Juârez Acoustic Guitar, 38 Inch Cutaway, 038C with Bag, Strings, Pick and Strap, Black (Acoustic Guitar Kit, Red Sunburst)\n",
      "Price: ₹ 2,199\n",
      "--------------------------------------------------\n",
      "Product:  Juârez Lindenwood Acoustic Guitar, 38 Inches Cutaway, JRZ38C With Bag, Strings, Pick And Strap, Blue\n",
      "Price: ₹ 2,199\n",
      "--------------------------------------------------\n",
      "Product:  Juârez Acoustic Guitar Kit, 38 Inch Cutaway, 038C with Bag, Strings, Pick and Strap, Black\n",
      "Price: ₹ 2,199\n",
      "--------------------------------------------------\n",
      "Product:  Juârez Acoustic Guitar, 38 Inch Cutaway, 038C with Bag, Strings, Pick and Strap, Black (Acoustic Guitar Kit, ASH)\n",
      "Price: ₹ 2,199\n",
      "--------------------------------------------------\n",
      "Product:  Juârez Acoustic Guitar, 38 Inch Cutaway, 038C with Bag, Strings, Pick and Strap, Black (Acoustic Guitar Kit, ZEBRA)\n",
      "Price: ₹ 2,199\n",
      "--------------------------------------------------\n",
      "Product:  Juârez Acoustic Guitar, 38 Inch Cutaway, 038C with Bag, Strings, Pick and Strap, Black (Acoustic Guitar Kit, FUNKY)\n",
      "Price: ₹ 2,199\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"span.a-price-whole\"}\n  (Session info: chrome=123.0.6312.123); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF66BBD7032+63090]\n\t(No symbol) [0x00007FF66BB42C82]\n\t(No symbol) [0x00007FF66B9DEC65]\n\t(No symbol) [0x00007FF66BA2499D]\n\t(No symbol) [0x00007FF66BA24ADC]\n\t(No symbol) [0x00007FF66BA1A0AC]\n\t(No symbol) [0x00007FF66BA4701F]\n\t(No symbol) [0x00007FF66BA1A00A]\n\t(No symbol) [0x00007FF66BA471F0]\n\t(No symbol) [0x00007FF66BA63412]\n\t(No symbol) [0x00007FF66BA46D83]\n\t(No symbol) [0x00007FF66BA183A8]\n\t(No symbol) [0x00007FF66BA19441]\n\tGetHandleVerifier [0x00007FF66BFD25AD+4238317]\n\tGetHandleVerifier [0x00007FF66C00F70D+4488525]\n\tGetHandleVerifier [0x00007FF66C0079EF+4456495]\n\tGetHandleVerifier [0x00007FF66BCB0576+953270]\n\t(No symbol) [0x00007FF66BB4E54F]\n\t(No symbol) [0x00007FF66BB49224]\n\t(No symbol) [0x00007FF66BB4935B]\n\t(No symbol) [0x00007FF66BB39B94]\n\tBaseThreadInitThunk [0x00007FF8430B7344+20]\n\tRtlUserThreadStart [0x00007FF8444C26B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     33\u001b[0m     product_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the product name you want to search on Amazon India: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     search_amazon(product_name)\n",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m, in \u001b[0;36msearch_amazon\u001b[1;34m(product_name)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m product \u001b[38;5;129;01min\u001b[39;00m products:\n\u001b[0;32m     22\u001b[0m     product_title \u001b[38;5;241m=\u001b[39m product\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspan.a-text-normal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m---> 23\u001b[0m     product_price \u001b[38;5;241m=\u001b[39m product\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspan.a-price-whole\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct: \u001b[39m\u001b[38;5;124m\"\u001b[39m, product_title)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:417\u001b[0m, in \u001b[0;36mWebElement.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    414\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    415\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(Command\u001b[38;5;241m.\u001b[39mFIND_CHILD_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39mexecute(command, params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"span.a-price-whole\"}\n  (Session info: chrome=123.0.6312.123); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF66BBD7032+63090]\n\t(No symbol) [0x00007FF66BB42C82]\n\t(No symbol) [0x00007FF66B9DEC65]\n\t(No symbol) [0x00007FF66BA2499D]\n\t(No symbol) [0x00007FF66BA24ADC]\n\t(No symbol) [0x00007FF66BA1A0AC]\n\t(No symbol) [0x00007FF66BA4701F]\n\t(No symbol) [0x00007FF66BA1A00A]\n\t(No symbol) [0x00007FF66BA471F0]\n\t(No symbol) [0x00007FF66BA63412]\n\t(No symbol) [0x00007FF66BA46D83]\n\t(No symbol) [0x00007FF66BA183A8]\n\t(No symbol) [0x00007FF66BA19441]\n\tGetHandleVerifier [0x00007FF66BFD25AD+4238317]\n\tGetHandleVerifier [0x00007FF66C00F70D+4488525]\n\tGetHandleVerifier [0x00007FF66C0079EF+4456495]\n\tGetHandleVerifier [0x00007FF66BCB0576+953270]\n\t(No symbol) [0x00007FF66BB4E54F]\n\t(No symbol) [0x00007FF66BB49224]\n\t(No symbol) [0x00007FF66BB4935B]\n\t(No symbol) [0x00007FF66BB39B94]\n\tBaseThreadInitThunk [0x00007FF8430B7344+20]\n\tRtlUserThreadStart [0x00007FF8444C26B1+33]\n"
     ]
    }
   ],
   "source": [
    "#Write a python program which searches all the product under a particular product from www.amazon.in. The\n",
    "#product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for\n",
    "#guitars.\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "def search_amazon(product_name):\n",
    "    driver = webdriver.Chrome()  # Make sure you have chromedriver installed and in PATH\n",
    "    driver.get(\"https://www.amazon.in\")\n",
    "    search_box = driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "    search_box.send_keys(product_name)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    time.sleep(3)  # Allow time for the page to load\n",
    "    \n",
    "    products = driver.find_elements(By.CSS_SELECTOR, \"div[data-component-type='s-search-result']\")\n",
    "    \n",
    "    if products:\n",
    "        print(\"Products found for '{}' on Amazon India:\".format(product_name))\n",
    "        for product in products:\n",
    "            product_title = product.find_element(By.CSS_SELECTOR, \"span.a-text-normal\").text\n",
    "            product_price = product.find_element(By.CSS_SELECTOR, \"span.a-price-whole\").text\n",
    "            print(\"-\" * 50)\n",
    "            print(\"Product: \", product_title)\n",
    "            print(\"Price: ₹\", product_price)\n",
    "    else:\n",
    "        print(\"No products found for '{}' on Amazon India\".format(product_name))\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    product_name = input(\"Enter the product name you want to search on Amazon India: \")\n",
    "    search_amazon(product_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fbc0c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product name you want to search on Amazon India: guitar\n",
      "Enter the product name you want to search on Amazon India: jeans\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def scrape_product_details(driver, product):\n",
    "    try:\n",
    "        brand_name = product.find_element(By.CSS_SELECTOR, \"span.a-size-base-plus.a-color-base\").text\n",
    "    except:\n",
    "        brand_name = \"-\"\n",
    "    \n",
    "    try:\n",
    "        product_name = product.find_element(By.CSS_SELECTOR, \"span.a-size-base-plus.a-color-base.a-text-normal\").text\n",
    "    except:\n",
    "        product_name = \"-\"\n",
    "    \n",
    "    try:\n",
    "        price = product.find_element(By.CSS_SELECTOR, \"span.a-price-whole\").text\n",
    "    except:\n",
    "        price = \"-\"\n",
    "    \n",
    "    try:\n",
    "        return_exchange = product.find_element(By.CSS_SELECTOR, \"div.a-row.a-size-base.a-color-secondary\").text\n",
    "    except:\n",
    "        return_exchange = \"-\"\n",
    "    \n",
    "    try:\n",
    "        expected_delivery = product.find_element(By.CSS_SELECTOR, \"span.a-text-bold\").text\n",
    "    except:\n",
    "        expected_delivery = \"-\"\n",
    "    \n",
    "    try:\n",
    "        availability = product.find_element(By.CSS_SELECTOR, \"span.a-size-base.a-color-success\").text\n",
    "    except:\n",
    "        availability = \"-\"\n",
    "    \n",
    "    try:\n",
    "        product_url = product.find_element(By.CSS_SELECTOR, \"a.a-link-normal.a-text-normal\").get_attribute('href')\n",
    "    except:\n",
    "        product_url = \"-\"\n",
    "    \n",
    "    return {\n",
    "        \"Brand Name\": brand_name,\n",
    "        \"Name of the Product\": product_name,\n",
    "        \"Price\": price,\n",
    "        \"Return/Exchange\": return_exchange,\n",
    "        \"Expected Delivery\": expected_delivery,\n",
    "        \"Availability\": availability,\n",
    "        \"Product URL\": product_url\n",
    "    }\n",
    "\n",
    "def search_and_scrape_amazon(product_name, pages):\n",
    "    driver = webdriver.Chrome()  # Make sure you have chromedriver installed and in PATH\n",
    "    driver.get(\"https://www.amazon.in\")\n",
    "    search_box = driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "    search_box.send_keys(product_name)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    time.sleep(3)  # Allow time for the page to load\n",
    "    \n",
    "    products_data = []\n",
    "    \n",
    "    for page in range(1, pages + 1):\n",
    "        products = driver.find_elements(By.CSS_SELECTOR, \"div[data-component-type='s-search-result']\")\n",
    "        \n",
    "        for product in products:\n",
    "            product_data = scrape_product_details(driver, product)\n",
    "            products_data.append(product_data)\n",
    "        \n",
    "        try:\n",
    "            next_page_button = driver.find_element(By.CSS_SELECTOR, \".a-last\")\n",
    "            next_page_button.click()\n",
    "            time.sleep(2)  # Allow time for the page to load\n",
    "        except:\n",
    "            break\n",
    "    \n",
    "    df = pd.DataFrame(products_data)\n",
    "    df.to_csv(\"amazon_products.csv\", index=False)\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    product_name = input(\"Enter the product name you want to search on Amazon India: \")\n",
    "    search_and_scrape_amazon(product_name, pages=3)\n",
    "def scrape_product_details(driver, product):\n",
    "    try:\n",
    "        brand_name = product.find_element(By.CSS_SELECTOR, \"span.a-size-base-plus.a-color-base\").text\n",
    "    except:\n",
    "        brand_name = \"-\"\n",
    "    \n",
    "    try:\n",
    "        product_name = product.find_element(By.CSS_SELECTOR, \"span.a-size-base-plus.a-color-base.a-text-normal\").text\n",
    "    except:\n",
    "        product_name = \"-\"\n",
    "    \n",
    "    try:\n",
    "        price = product.find_element(By.CSS_SELECTOR, \"span.a-price-whole\").text\n",
    "    except:\n",
    "        price = \"-\"\n",
    "    \n",
    "    try:\n",
    "        return_exchange = product.find_element(By.CSS_SELECTOR, \"div.a-row.a-size-base.a-color-secondary\").text\n",
    "    except:\n",
    "        return_exchange = \"-\"\n",
    "    \n",
    "    try:\n",
    "        expected_delivery = product.find_element(By.CSS_SELECTOR, \"span.a-text-bold\").text\n",
    "    except:\n",
    "        expected_delivery = \"-\"\n",
    "    \n",
    "    try:\n",
    "        availability = product.find_element(By.CSS_SELECTOR, \"span.a-size-base.a-color-success\").text\n",
    "    except:\n",
    "        availability = \"-\"\n",
    "    \n",
    "    try:\n",
    "        product_url = product.find_element(By.CSS_SELECTOR, \"a.a-link-normal.a-text-normal\").get_attribute('href')\n",
    "    except:\n",
    "        product_url = \"-\"\n",
    "    \n",
    "    return {\n",
    "        \"Brand Name\": brand_name,\n",
    "        \"Name of the Product\": product_name,\n",
    "        \"Price\": price,\n",
    "        \"Return/Exchange\": return_exchange,\n",
    "        \"Expected Delivery\": expected_delivery,\n",
    "        \"Availability\": availability,\n",
    "        \"Product URL\": product_url\n",
    "    }\n",
    "\n",
    "def search_and_scrape_amazon(product_name, pages):\n",
    "    driver = webdriver.Chrome()  # Make sure you have chromedriver installed and in PATH\n",
    "    driver.get(\"https://www.amazon.in\")\n",
    "    search_box = driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "    search_box.send_keys(product_name)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    time.sleep(3)  # Allow time for the page to load\n",
    "    \n",
    "    products_data = []\n",
    "    \n",
    "    for page in range(1, pages + 1):\n",
    "        products = driver.find_elements(By.CSS_SELECTOR, \"div[data-component-type='s-search-result']\")\n",
    "        \n",
    "        for product in products:\n",
    "            product_data = scrape_product_details(driver, product)\n",
    "            products_data.append(product_data)\n",
    "        \n",
    "        try:\n",
    "            next_page_button = driver.find_element(By.CSS_SELECTOR, \".a-last\")\n",
    "            next_page_button.click()\n",
    "            time.sleep(2)  # Allow time for the page to load\n",
    "        except:\n",
    "            break\n",
    "    \n",
    "    df = pd.DataFrame(products_data)\n",
    "    df.to_csv(\"amazon_products.csv\", index=False)\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    product_name = input(\"Enter the product name you want to search on Amazon India: \")\n",
    "    search_and_scrape_amazon(product_name, pages=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f02de6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 10 images for 'fruits'\n",
      "Downloaded 0 images for 'cars'\n",
      "Downloaded 0 images for 'Machine Learning'\n",
      "Downloaded 0 images for 'Guitar'\n",
      "Downloaded 0 images for 'Cakes'\n"
     ]
    }
   ],
   "source": [
    "#Write a python program to access the search bar and search button on images.google.com and scrape 10\n",
    "#images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’. \n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_images(keyword, num_images):\n",
    "    driver = webdriver.Chrome()  # Make sure you have chromedriver installed and in PATH\n",
    "    driver.get(\"https://www.google.com/imghp\")\n",
    "    \n",
    "    search_bar = driver.find_element(By.NAME, \"q\")\n",
    "    search_bar.send_keys(keyword)\n",
    "    search_bar.send_keys(Keys.RETURN)\n",
    "    time.sleep(2)  # Allow time for the page to load\n",
    "    \n",
    "    images = []\n",
    "    while len(images) < num_images:\n",
    "        # Scroll to load more images\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait for more images to load\n",
    "        \n",
    "        # Extract image URLs\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        img_tags = soup.find_all('img', class_='rg_i')\n",
    "        for img_tag in img_tags:\n",
    "            try:\n",
    "                img_url = img_tag['data-src']\n",
    "                if img_url.startswith(\"http\"):\n",
    "                    images.append(img_url)\n",
    "                    if len(images) == num_images:\n",
    "                        break\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "        # Clicking on the last thumbnail to load more images\n",
    "        try:\n",
    "            driver.find_element(By.CSS_SELECTOR, \".mye4qd\").click()\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    directory = 'images_' + keyword\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Download images\n",
    "    for i, image_url in enumerate(images):\n",
    "        response = requests.get(image_url)\n",
    "        with open(os.path.join(directory, f\"{keyword}_{i+1}.jpg\"), 'wb') as file:\n",
    "            file.write(response.content)\n",
    "    \n",
    "    print(f\"Downloaded {len(images)} images for '{keyword}'\")\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    keywords = ['fruits', 'cars', 'Machine Learning', 'Guitar', 'Cakes']\n",
    "    num_images_per_keyword = 10\n",
    "    for keyword in keywords:\n",
    "        scrape_images(keyword, num_images_per_keyword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "218ed0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the smartphone you want to search on Flipkart: oppo\n"
     ]
    }
   ],
   "source": [
    "#Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com\n",
    "#and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand\n",
    "#Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "#“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the\n",
    "#details is missing then replace it by “- “. Save your results in a dataframe and CSV. \n",
    "\n",
    "\n",
    "def scrape_smartphone_details(driver):\n",
    "    smartphones = driver.find_elements(By.CSS_SELECTOR, \"div._1AtVbE\")\n",
    "    smartphone_details = []\n",
    "    for smartphone in smartphones:\n",
    "        details = {}\n",
    "        try:\n",
    "            details[\"Brand Name\"] = smartphone.find_element(By.CSS_SELECTOR, \"div._4rR01T\").text\n",
    "        except:\n",
    "            details[\"Brand Name\"] = \"-\"\n",
    "        \n",
    "        try:\n",
    "            details[\"Smartphone Name\"] = smartphone.find_element(By.CSS_SELECTOR, \"a._2rpwqI\").text\n",
    "        except:\n",
    "            details[\"Smartphone Name\"] = \"-\"\n",
    "        \n",
    "        try:\n",
    "            details[\"Colour\"] = smartphone.find_element(By.CSS_SELECTOR, \"a._1Wb-Sx\").text\n",
    "        except:\n",
    "            details[\"Colour\"] = \"-\"\n",
    "        \n",
    "        features = smartphone.find_elements(By.CSS_SELECTOR, \"li.tVe95H\")\n",
    "        for feature in features:\n",
    "            text = feature.text\n",
    "            if \"RAM\" in text:\n",
    "                details[\"RAM\"] = text.split(\"|\")[0].strip()\n",
    "            elif \"ROM\" in text:\n",
    "                details[\"Storage(ROM)\"] = text.split(\"|\")[0].strip()\n",
    "            elif \"Primary Camera\" in text:\n",
    "                details[\"Primary Camera\"] = text.split(\"|\")[0].strip()\n",
    "            elif \"Secondary Camera\" in text:\n",
    "                details[\"Secondary Camera\"] = text.split(\"|\")[0].strip()\n",
    "            elif \"Display Size\" in text:\n",
    "                details[\"Display Size\"] = text.split(\"|\")[0].strip()\n",
    "            elif \"Battery Capacity\" in text:\n",
    "                details[\"Battery Capacity\"] = text.split(\"|\")[0].strip()\n",
    "        \n",
    "        try:\n",
    "            details[\"Price\"] = smartphone.find_element(By.CSS_SELECTOR, \"div._30jeq3._1_WHN1\").text\n",
    "        except:\n",
    "            details[\"Price\"] = \"-\"\n",
    "        \n",
    "        try:\n",
    "            details[\"Product URL\"] = smartphone.find_element(By.CSS_SELECTOR, \"a._1fQZEK\").get_attribute('href')\n",
    "        except:\n",
    "            details[\"Product URL\"] = \"-\"\n",
    "        \n",
    "        smartphone_details.append(details)\n",
    "    \n",
    "    return smartphone_details\n",
    "\n",
    "def search_and_scrape_flipkart(product_name):\n",
    "    driver = webdriver.Chrome()  # Make sure you have chromedriver installed and in PATH\n",
    "    driver.get(\"https://www.flipkart.com\")\n",
    "    \n",
    "    # Close the login popup if it appears\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, \"button._2KpZ6l._2doB4z\").click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    search_bar = driver.find_element(By.CSS_SELECTOR, \"input[type='text']\")\n",
    "    search_bar.send_keys(product_name)\n",
    "    search_bar.send_keys(Keys.RETURN)\n",
    "    time.sleep(3)  # Allow time for the page to load\n",
    "    \n",
    "    smartphone_details = scrape_smartphone_details(driver)\n",
    "    df = pd.DataFrame(smartphone_details)\n",
    "    df.to_csv(\"flipkart_smartphones.csv\", index=False)\n",
    "    \n",
    "    #driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    product_name = input(\"Enter the smartphone you want to search on Flipkart: \")\n",
    "    search_and_scrape_flipkart(product_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39bfab8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the city name to search for its coordinates on Google Maps: Pune\n",
      "Coordinates not found for the specified city.\n"
     ]
    }
   ],
   "source": [
    "def scrape_coordinates(city):\n",
    "    driver = webdriver.Chrome()  # Make sure you have chromedriver installed and in PATH\n",
    "    driver.get(\"https://www.google.com/maps\")\n",
    "    \n",
    "    search_box = driver.find_element(By.ID, \"searchboxinput\")\n",
    "    search_box.send_keys(city)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    time.sleep(3)  # Allow time for the page to load\n",
    "    \n",
    "    try:\n",
    "        url = driver.current_url\n",
    "        if \"@,\" in url:\n",
    "            coordinates = url.split(\"@\")[1].split(\",\")[0:2]\n",
    "            latitude = coordinates[0]\n",
    "            longitude = coordinates[1]\n",
    "            print(f\"Latitude: {latitude}, Longitude: {longitude}\")\n",
    "        else:\n",
    "            print(\"Coordinates not found for the specified city.\")\n",
    "    except:\n",
    "        print(\"Error occurred while scraping coordinates.\")\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    city = input(\"Enter the city name to search for its coordinates on Google Maps: \")\n",
    "    scrape_coordinates(city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b417e0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to best_gaming_laptops.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_gaming_laptops():\n",
    "    driver = webdriver.Chrome()  # Make sure you have chromedriver installed and in PATH\n",
    "    driver.get(\"https://www.digit.in/top-products/best-gaming-laptops-40.html\")\n",
    "\n",
    "    laptops = []\n",
    "    laptop_list = driver.find_elements(By.CLASS_NAME, \"TopNumbeHeading\")\n",
    "    for laptop in laptop_list:\n",
    "        details = {}\n",
    "        details[\"Name\"] = laptop.find_element(By.CLASS_NAME, \"TopNumbeHeadingname\").text.strip()\n",
    "        details[\"Price\"] = laptop.find_element(By.CLASS_NAME, \"smprice\").text.strip()\n",
    "        details[\"OS\"] = laptop.find_elements(By.CLASS_NAME, \"Spcs-details\")[0].find_elements(By.CLASS_NAME, \"Spcs-key\")[1].text.strip()\n",
    "        details[\"Display\"] = laptop.find_elements(By.CLASS_NAME, \"Spcs-details\")[1].find_elements(By.CLASS_NAME, \"Spcs-key\")[1].text.strip()\n",
    "        details[\"Processor\"] = laptop.find_elements(By.CLASS_NAME, \"Spcs-details\")[2].find_elements(By.CLASS_NAME, \"Spcs-key\")[1].text.strip()\n",
    "        details[\"Memory\"] = laptop.find_elements(By.CLASS_NAME, \"Spcs-details\")[3].find_elements(By.CLASS_NAME, \"Spcs-key\")[1].text.strip()\n",
    "        details[\"Weight\"] = laptop.find_elements(By.CLASS_NAME, \"Spcs-details\")[4].find_elements(By.CLASS_NAME, \"Spcs-key\")[1].text.strip()\n",
    "        details[\"Description\"] = laptop.find_element(By.CLASS_NAME, \"Section-center\").text.strip()\n",
    "        laptops.append(details)\n",
    "\n",
    "    driver.quit()\n",
    "    return laptops\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = scrape_gaming_laptops()\n",
    "    save_to_csv(data, \"best_gaming_laptops.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644593ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a9a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c56885f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//button[@data-testid='cookie-policy-dialog-accept-button']\"}\n  (Session info: chrome=123.0.6312.123); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF66BBD7032+63090]\n\t(No symbol) [0x00007FF66BB42C82]\n\t(No symbol) [0x00007FF66B9DEC65]\n\t(No symbol) [0x00007FF66BA2499D]\n\t(No symbol) [0x00007FF66BA24ADC]\n\t(No symbol) [0x00007FF66BA65B37]\n\t(No symbol) [0x00007FF66BA4701F]\n\t(No symbol) [0x00007FF66BA63412]\n\t(No symbol) [0x00007FF66BA46D83]\n\t(No symbol) [0x00007FF66BA183A8]\n\t(No symbol) [0x00007FF66BA19441]\n\tGetHandleVerifier [0x00007FF66BFD25AD+4238317]\n\tGetHandleVerifier [0x00007FF66C00F70D+4488525]\n\tGetHandleVerifier [0x00007FF66C0079EF+4456495]\n\tGetHandleVerifier [0x00007FF66BCB0576+953270]\n\t(No symbol) [0x00007FF66BB4E54F]\n\t(No symbol) [0x00007FF66BB49224]\n\t(No symbol) [0x00007FF66BB4935B]\n\t(No symbol) [0x00007FF66BB39B94]\n\tBaseThreadInitThunk [0x00007FF8430B7344+20]\n\tRtlUserThreadStart [0x00007FF8444C26B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 48\u001b[0m     data \u001b[38;5;241m=\u001b[39m scrape_billionaires()\n\u001b[0;32m     49\u001b[0m     save_to_csv(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforbes_billionaires.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m, in \u001b[0;36mscrape_billionaires\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m billionaires \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Find and click the \"Accept\" button for cookies\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m accept_button \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//button[@data-testid=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcookie-policy-dialog-accept-button\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m accept_button\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Keep clicking the \"Show more\" button until it's not found\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    738\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    739\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//button[@data-testid='cookie-policy-dialog-accept-button']\"}\n  (Session info: chrome=123.0.6312.123); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF66BBD7032+63090]\n\t(No symbol) [0x00007FF66BB42C82]\n\t(No symbol) [0x00007FF66B9DEC65]\n\t(No symbol) [0x00007FF66BA2499D]\n\t(No symbol) [0x00007FF66BA24ADC]\n\t(No symbol) [0x00007FF66BA65B37]\n\t(No symbol) [0x00007FF66BA4701F]\n\t(No symbol) [0x00007FF66BA63412]\n\t(No symbol) [0x00007FF66BA46D83]\n\t(No symbol) [0x00007FF66BA183A8]\n\t(No symbol) [0x00007FF66BA19441]\n\tGetHandleVerifier [0x00007FF66BFD25AD+4238317]\n\tGetHandleVerifier [0x00007FF66C00F70D+4488525]\n\tGetHandleVerifier [0x00007FF66C0079EF+4456495]\n\tGetHandleVerifier [0x00007FF66BCB0576+953270]\n\t(No symbol) [0x00007FF66BB4E54F]\n\t(No symbol) [0x00007FF66BB49224]\n\t(No symbol) [0x00007FF66BB4935B]\n\t(No symbol) [0x00007FF66BB39B94]\n\tBaseThreadInitThunk [0x00007FF8430B7344+20]\n\tRtlUserThreadStart [0x00007FF8444C26B1+33]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def scrape_billionaires():\n",
    "    driver = webdriver.Chrome()  # Make sure you have chromedriver installed and in PATH\n",
    "    url = \"https://www.forbes.com/billionaires/\"\n",
    "    driver.get(url)\n",
    "\n",
    "    billionaires = []\n",
    "\n",
    "    # Find and click the \"Accept\" button for cookies\n",
    "    accept_button = driver.find_element(By.XPATH, \"//button[@data-testid='cookie-policy-dialog-accept-button']\")\n",
    "    accept_button.click()\n",
    "\n",
    "    # Keep clicking the \"Show more\" button until it's not found\n",
    "    while True:\n",
    "        try:\n",
    "            show_more_button = driver.find_element(By.XPATH, \"//button[contains(@class, 'expander-icon-container')]\")\n",
    "            show_more_button.click()\n",
    "            time.sleep(1)  # Allow time for more profiles to load\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    # Find all billionaire profiles\n",
    "    profiles = driver.find_elements(By.XPATH, \"//div[@class='rank']\")\n",
    "    for profile in profiles:\n",
    "        details = {}\n",
    "        details[\"Rank\"] = profile.find_element(By.XPATH, \"./div[@class='rank']\").text.strip()\n",
    "        details[\"Name\"] = profile.find_element(By.XPATH, \"./div[@class='personName']\").text.strip()\n",
    "        details[\"Net worth\"] = profile.find_element(By.XPATH, \"./div[@class='netWorth']\").text.strip()\n",
    "        details[\"Age\"] = profile.find_element(By.XPATH, \"./div[@class='age']\").text.strip()\n",
    "        details[\"Citizenship\"] = profile.find_element(By.XPATH, \"./div[@class='countryOfCitizenship']\").text.strip()\n",
    "        details[\"Source\"] = profile.find_element(By.XPATH, \"./div[@class='source']\").text.strip()\n",
    "        details[\"Industry\"] = profile.find_element(By.XPATH, \"./div[@class='category']\").text.strip()\n",
    "        billionaires.append(details)\n",
    "\n",
    "    driver.quit()\n",
    "    return billionaires\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = scrape_billionaires()\n",
    "    save_to_csv(data, \"forbes_billionaires.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7caf378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the YouTube video URL: wheels on bus\n"
     ]
    },
    {
     "ename": "InvalidArgumentException",
     "evalue": "Message: invalid argument\n  (Session info: chrome=123.0.6312.123)\nStacktrace:\n\tGetHandleVerifier [0x00007FF66BBD7032+63090]\n\t(No symbol) [0x00007FF66BB42C82]\n\t(No symbol) [0x00007FF66B9DEB1D]\n\t(No symbol) [0x00007FF66B9CC76D]\n\t(No symbol) [0x00007FF66B9CB100]\n\t(No symbol) [0x00007FF66B9CB8BC]\n\t(No symbol) [0x00007FF66B9E14AD]\n\t(No symbol) [0x00007FF66BA63D67]\n\t(No symbol) [0x00007FF66BA46FDA]\n\t(No symbol) [0x00007FF66BA63412]\n\t(No symbol) [0x00007FF66BA46D83]\n\t(No symbol) [0x00007FF66BA183A8]\n\t(No symbol) [0x00007FF66BA19441]\n\tGetHandleVerifier [0x00007FF66BFD25AD+4238317]\n\tGetHandleVerifier [0x00007FF66C00F70D+4488525]\n\tGetHandleVerifier [0x00007FF66C0079EF+4456495]\n\tGetHandleVerifier [0x00007FF66BCB0576+953270]\n\t(No symbol) [0x00007FF66BB4E54F]\n\t(No symbol) [0x00007FF66BB49224]\n\t(No symbol) [0x00007FF66BB4935B]\n\t(No symbol) [0x00007FF66BB39B94]\n\tBaseThreadInitThunk [0x00007FF8430B7344+20]\n\tRtlUserThreadStart [0x00007FF8444C26B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m video_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the YouTube video URL: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m num_comments \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m---> 43\u001b[0m comments \u001b[38;5;241m=\u001b[39m scrape_youtube_comments(video_url, num_comments)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m comments:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(comment)\n",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m, in \u001b[0;36mscrape_youtube_comments\u001b[1;34m(video_url, num_comments)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_youtube_comments\u001b[39m(video_url, num_comments):\n\u001b[0;32m      7\u001b[0m     driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome()  \u001b[38;5;66;03m# Make sure you have chromedriver installed and in PATH\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(video_url)\n\u001b[0;32m      9\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Give time for the page to load\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Scroll down to load comments\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:356\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: url})\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mInvalidArgumentException\u001b[0m: Message: invalid argument\n  (Session info: chrome=123.0.6312.123)\nStacktrace:\n\tGetHandleVerifier [0x00007FF66BBD7032+63090]\n\t(No symbol) [0x00007FF66BB42C82]\n\t(No symbol) [0x00007FF66B9DEB1D]\n\t(No symbol) [0x00007FF66B9CC76D]\n\t(No symbol) [0x00007FF66B9CB100]\n\t(No symbol) [0x00007FF66B9CB8BC]\n\t(No symbol) [0x00007FF66B9E14AD]\n\t(No symbol) [0x00007FF66BA63D67]\n\t(No symbol) [0x00007FF66BA46FDA]\n\t(No symbol) [0x00007FF66BA63412]\n\t(No symbol) [0x00007FF66BA46D83]\n\t(No symbol) [0x00007FF66BA183A8]\n\t(No symbol) [0x00007FF66BA19441]\n\tGetHandleVerifier [0x00007FF66BFD25AD+4238317]\n\tGetHandleVerifier [0x00007FF66C00F70D+4488525]\n\tGetHandleVerifier [0x00007FF66C0079EF+4456495]\n\tGetHandleVerifier [0x00007FF66BCB0576+953270]\n\t(No symbol) [0x00007FF66BB4E54F]\n\t(No symbol) [0x00007FF66BB49224]\n\t(No symbol) [0x00007FF66BB4935B]\n\t(No symbol) [0x00007FF66BB39B94]\n\tBaseThreadInitThunk [0x00007FF8430B7344+20]\n\tRtlUserThreadStart [0x00007FF8444C26B1+33]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "def scrape_youtube_comments(video_url, num_comments):\n",
    "    driver = webdriver.Chrome()  # Make sure you have chromedriver installed and in PATH\n",
    "    driver.get(video_url)\n",
    "    time.sleep(5)  # Give time for the page to load\n",
    "\n",
    "    # Scroll down to load comments\n",
    "    SCROLL_PAUSE_TIME = 5\n",
    "    last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extract comments, upvotes, and time posted\n",
    "    comments = []\n",
    "    comment_elements = driver.find_elements(By.CSS_SELECTOR, \"#content-text\")\n",
    "    upvote_elements = driver.find_elements(By.CSS_SELECTOR, \"#vote-count-middle\")\n",
    "    time_elements = driver.find_elements(By.CSS_SELECTOR, \"#header-author > yt-formatted-string > a > #published-time-text\")\n",
    "\n",
    "    for comment, upvote, time_element in zip(comment_elements, upvote_elements, time_elements):\n",
    "        comment_text = comment.text.strip()\n",
    "        upvote_count = upvote.text.strip()\n",
    "        time_posted = time_element.get_attribute(\"aria-label\").split(\" \")[-2:]\n",
    "        comments.append({\"Comment\": comment_text, \"Upvotes\": upvote_count, \"Time Posted\": \" \".join(time_posted)})\n",
    "\n",
    "        if len(comments) >= num_comments:\n",
    "            break\n",
    "\n",
    "    driver.quit()\n",
    "    return comments\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_url = input(\"Enter the YouTube video URL: \")\n",
    "    num_comments = 500\n",
    "    comments = scrape_youtube_comments(video_url, num_comments)\n",
    "    for comment in comments:\n",
    "        print(comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fae7c1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the YouTube video URL: http://www.youtube.com/watch?v=-wtIMTCHWuI\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "def scrape_youtube_comments(video_url, num_comments):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--disable-extensions')\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--no-sandbox')\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)  # Use headless mode to speed up scraping\n",
    "    driver.get(video_url)\n",
    "    time.sleep(5)  # Give time for the page to load\n",
    "\n",
    "    # Scroll down to load comments\n",
    "    SCROLL_PAUSE_TIME = 5\n",
    "    last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extract comments, upvotes, and time posted\n",
    "    comments = []\n",
    "    comment_elements = driver.find_elements(By.CSS_SELECTOR, \"#content-text\")\n",
    "    upvote_elements = driver.find_elements(By.CSS_SELECTOR, \"#vote-count-middle\")\n",
    "    time_elements = driver.find_elements(By.CSS_SELECTOR, \"#header-author > yt-formatted-string > a > #published-time-text\")\n",
    "\n",
    "    for comment, upvote, time_element in zip(comment_elements, upvote_elements, time_elements):\n",
    "        comment_text = comment.text.strip()\n",
    "        upvote_count = upvote.text.strip()\n",
    "        time_posted = time_element.get_attribute(\"aria-label\").split(\" \")[-2:]\n",
    "        comments.append({\"Comment\": comment_text, \"Upvotes\": upvote_count, \"Time Posted\": \" \".join(time_posted)})\n",
    "\n",
    "        if len(comments) >= num_comments:\n",
    "            break\n",
    "\n",
    "    driver.quit()\n",
    "    return comments\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_url = input(\"Enter the YouTube video URL: \")\n",
    "    num_comments = 500\n",
    "    comments = scrape_youtube_comments(video_url, num_comments)\n",
    "    for comment in comments:\n",
    "        print(comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d54ab7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout occurred while waiting for hostels to load\n",
      "No hostels data retrieved.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_hostels_in_london():\n",
    "    driver = webdriver.Chrome()  # Make sure you have chromedriver installed and in PATH\n",
    "    url = \"https://www.hostelworld.com/hostels/London/England\"\n",
    "    driver.get(url)\n",
    "\n",
    "    hostels = []\n",
    "\n",
    "    try:\n",
    "        hostel_list = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"property-card\")))\n",
    "    except TimeoutException:\n",
    "        print(\"Timeout occurred while waiting for hostels to load\")\n",
    "        driver.quit()\n",
    "        return []\n",
    "\n",
    "    for hostel in hostel_list:\n",
    "        details = {}\n",
    "        details[\"Hostel Name\"] = hostel.find_element(By.CLASS_NAME, \"title\").text.strip()\n",
    "\n",
    "        distance_elem = hostel.find_element(By.CLASS_NAME, \"description\")\n",
    "        details[\"Distance from City Centre\"] = distance_elem.text.strip()\n",
    "\n",
    "        ratings_elem = hostel.find_element(By.CLASS_NAME, \"score\")\n",
    "        details[\"Ratings\"] = ratings_elem.text.strip()\n",
    "\n",
    "        reviews_elem = hostel.find_element(By.CLASS_NAME, \"reviews\")\n",
    "        details[\"Total Reviews\"] = reviews_elem.text.strip().split()[0]\n",
    "\n",
    "        overall_reviews_elem = hostel.find_element(By.CLASS_NAME, \"keyword\")\n",
    "        details[\"Overall Reviews\"] = overall_reviews_elem.text.strip()\n",
    "\n",
    "        price_elements = hostel.find_elements(By.CLASS_NAME, \"price-col\")\n",
    "        details[\"Privates from Price\"] = price_elements[0].text.strip() if price_elements else \"-\"\n",
    "        details[\"Dorms from Price\"] = price_elements[1].text.strip() if len(price_elements) > 1 else \"-\"\n",
    "\n",
    "        facilities_elem = hostel.find_element(By.CLASS_NAME, \"facilities-label\")\n",
    "        details[\"Facilities\"] = \", \".join([item.text.strip() for item in facilities_elem.find_elements(By.TAG_NAME, \"span\")])\n",
    "\n",
    "        description_elem = hostel.find_element(By.CLASS_NAME, \"rating-factors\")\n",
    "        details[\"Property Description\"] = description_elem.text.strip()\n",
    "\n",
    "        hostels.append(details)\n",
    "\n",
    "    driver.quit()\n",
    "    return hostels\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = scrape_hostels_in_london()\n",
    "    if data:\n",
    "        save_to_csv(data, \"hostels_in_london.csv\")\n",
    "    else:\n",
    "        print(\"No hostels data retrieved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
